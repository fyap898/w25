# Tutorial 10: Applied Transformers

In today's tutorial, we'll be discussing the heavily cited paper [Attention is All you Need](https://arxiv.org/abs/1706.03762).

We don't really have the computational resources to train our own transformer models, but we can play around with pre-trained models. I was able to run the [HuggingFace notebook](10-transformers.ipynb) on my CPU, hopefully it works on the lab computers as well (but Colab is always an option as well).
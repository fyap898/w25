{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Networks with Keras\n",
    "Based on the notebook of the same name by [Aurelien Geron](https://github.com/ageron/handson-ml3/blob/main/10_neural_nets_with_keras.ipynb).\n",
    "\n",
    "In this notebook, we'll take the theoretical concepts of the past few weeks and apply them using the [Keras](https://keras.io/) library. Keras is a high-level wrapper that was originally designed to make Tensorflow easier to use, then was merged into Tensorflow, and now is a general high-level wrapper on Tensorflow, PyTorch, and JAX frameworks. For many \"basic\" neural network tasks, Keras is a great choice.\n",
    "\n",
    "## Objectives\n",
    "- Understand the basic structure of a neural network\n",
    "- Understand how to work with Keras\n",
    "- Build and train a simple classifier\n",
    "- Explore some more features of the Keras/Tensorflow ecosystem\n",
    "\n",
    "First we'll load the necessary libraries and make sure we have the right versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore the data\n",
    "We'll be working with a very clean \"hello world\" type of dataset, but it's still a good idea to take a peek.\n",
    "\n",
    "`tf.keras.datasets` has a number of built-in popular datasets used for teaching exercises (like this one), benchmarking, and even some new research. The original version of this notebook used the Fashion MNIST dataset, but we'll use the \"classic\" MNIST dataset to relate things back to the 1989 paper that we read this week (or the 1998 version that I posted by accident, which is actually the origin of the MNIST dataset).\n",
    "\n",
    "The [load_data](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data) method returns a tuple of two tuples, one for the training data and one for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data() # I wish it was always this easy\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "\n",
    "# further split the training data into training and validation sets\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set contains 60,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel intensity is represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
    " color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index])\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that looks reasonable. What about the distribution of the classes? Let's plot some histograms to make sure the train/test/validation sets are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=10, label='train')\n",
    "plt.hist(y_test, bins=10, label='test')\n",
    "plt.hist(y_valid, bins=10, label='validation')\n",
    "plt.legend(loc='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a slight overrepresentation of 1s, but nothing egregious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "Keras v3 has [three ways of building models](https://keras.io/api/models/model/): sequential, functional, and subclassing. Keras v2 (the one incorporated into Tensorflow) has only sequential and functional. The sequential API is the simplest, but only works when you're building a simple stack of layers.\n",
    "\n",
    "For this model, we'll use 2 fully-connected layers (a departure from the original 1989 paper) and a softmax output layer with one neuron per class. The input layer will take our scaled 28x28 images and flatten them into a 1D array.\n",
    "\n",
    "❓ **Discussion questions**: \n",
    "- Why was the \"pyramid\" shape (many neurons in the first layer, fewer in the second, even fewer in the third, etc.) popular early on?\n",
    "- What is the current trend in selecting the number of neurons in a layer?\n",
    "- What is better, more layers or more neurons per layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42) # for reproducability\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the model, we can access each layer using the `layers` attribute and look at various things like the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1 = model.layers[1].get_weights()\n",
    "print(w1.shape)\n",
    "print(\"First 10 weights: \", w1[:10, 0])\n",
    "print(\"First 10 biases: \", b1[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the weights are randomly initialized, while biases are initialized to 0. This default behaviour (among other things) can be changed - [Reading the docs](https://keras.io/api/layers/initializers/) is always a good idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model\n",
    "[Compiling the model](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) is a bit of a misnomer - it's not compiling anything in the CS sense. A better word might be \"configuring\" the model. This is where you specify the loss function, the optimizer, and any metrics you want to track.\n",
    "\n",
    "❓ **Discussion questions**: \n",
    "- What should we use for loss, optimizer, and metrics? What are the options?\n",
    "- What is the difference between metrics and loss?\n",
    "- What is the difference between categorical and sparse categorical crossentropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Discussion questions**: \n",
    "- Does this seem like a good model?\n",
    "- How is the validation accuracy lower than training at the beginning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to shift the training curve by -1/2 epoch\n",
    "plt.figure(figsize=(8, 5))\n",
    "for key, style in zip(history.history, [\"r--\", \"r--.\", \"b-\", \"b-*\"]):\n",
    "    epochs = np.array(history.epoch) + (0 if key.startswith(\"val_\") else -0.5)\n",
    "    plt.plot(epochs, history.history[key], style, label=key)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.axis([-0.5, 29, 0., 1])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model to make predictions\n",
    "The accuracy looks great, but let's see how it behaves with some subjective examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:5]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Discussion questions**:\n",
    "- What are those 1s and 0s (and close to them)?\n",
    "- How can we map from the model output back to the class label?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_proba.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y_test[:5]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(y_test[index])\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go back and mess with the various parts of the model to see how it affects things, but 97.8% accuracy is pretty good. Of course, that was the MNIST dataset, which has been studied by many people for many years. Let's build a model for a different dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

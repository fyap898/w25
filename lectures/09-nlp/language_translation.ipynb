{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFvMqC9twYUe"
      },
      "source": [
        "# Fancier NLP\n",
        "\n",
        "Continuing our study of NLP methods, this notebook is based on the [Chapter 16](https://github.com/ageron/handson-ml3/blob/main/16_nlp_with_rnns_and_attention.ipynb) notebook from the Scikit-learn book."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect google drive for persistence\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "model_root = Path(\"/content/drive/MyDrive/SavedModels/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1YdhqGnpUp0",
        "outputId": "ddf3cbdb-89ab-4e27-e0fd-f720bf760b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Piq5se2pKzx"
      },
      "outputs": [],
      "source": [
        "# import stuff and check for GPU\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I8jZiVt4LpY"
      },
      "outputs": [],
      "source": [
        "# Load the IMDB dataset again\n",
        "raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n",
        "    name=\"imdb_reviews\",\n",
        "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
        "    as_supervised=True\n",
        ")\n",
        "tf.random.set_seed(42)\n",
        "train_set = raw_train_set.shuffle(5000, seed=42).batch(16).prefetch(1)\n",
        "valid_set = raw_valid_set.batch(16).prefetch(1)\n",
        "test_set = raw_test_set.batch(16).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at some of the data\n",
        "batch = next(iter(train_set))\n",
        "\n",
        "# batch is a tuple of X, y tensors, each length of the batch size\n",
        "print(f\"Positive review: {batch[1][0]}\")\n",
        "print(batch[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VY4iyrtJBn8",
        "outputId": "0244960e-e2d9-440b-cc33-d583153ea5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive review: 1\n",
            "tf.Tensor(b'This is a documentary that came out of the splendid work of a Canadian landscape photographer whose interest has long been in the ravages left on earth by the excavations or buildings of man. It begins with a vast factory complex crammed with people making a great variety of little things, parts of high-tech equipment presumably; it isn\\'t really made very clear. The emphasis is on how big the place is and how many people are there and how they\\'re herded around outside in little yellow jackets. The film also shows the photographer working on a tall structure to do a still of the array of these people outside the factory, and talking with his crew as he does so. This is a world of relentless industrialization. It\\'s a relief at least to know these soulless images aren\\'t going to be presented without a human voice, as is the case in Nikolaus Geyrhalter\\'s gleefully cold documentary about the food industry, \\'Our Daily Bread.\\' \\'Manufactured Landscapes\\' contains images of people scavenging e-waste and a town (many towns, really) being wiped out by the biggest dam ever, with a single plangent trademark shot of a little girl in the rubble of her own neighborhood eating out of a bowl using a pair of chopsticks almost bigger than she is. Some of these scenes, the ones with miserably underpaid workers slaving in dangerous and toxic places, might have been shot memorably by the premier engag\\xc3\\xa9 photographer Sebasti\\xc3\\xa3o Salgado. But this photographer isn\\'t as interested in seeing people up close. His orientation places him somewhere in between Salgado and the cold, neutral modern landscape photographs of Lewis Baltz.<br /><br />All this happens in China, of course, though there is earlier footage in black and white of the photographer working around a large shipbuilding site in Bangladesh. It is backed up by music in a New Age industrial style that is alternately soothing and oppressive. There are a good many stills of the photographer\\'s work--or were some of them made by the film crew? It isn\\'t made clear.<br /><br />Edward Burtynsky is the name of the photographer. We see people wandering through exhibitions of his beautiful work-- big dramatic prints of carefully composed view camera color images with a handsome glow. The irony is that Burtynsky makes such unique and glorious pictures of places that are essentially blighted, and to the ordinary eye are dispiriting and boring. He admits himself that he takes no political stand. When we are able to compare his images with those caught by the roaming eye of the film\\'s cinematographer Peter Mettler, Burtynsky\\'s work almost amounts to a kind of glorification, and hence falsification. But he is showing us places that, if we look closely, reveal their full dark story of ravage and neglect no matter how finely crafted the photographs of them may be.<br /><br />Logically, but not entirely fortunately, it is Burtynsky whose voice-overs narrate most of the film as it ranges over various sites. Burtynsky\\'s \"epiphanies\" may have inspired his decades of fine work, but they amount to nothing but truisms about how we\\'re changing the planet irreparably; are dependent on oil, which will run out; that China has come into the game of massive industrialization late, and so may burn out early with the depletion of fossil fuel. The interest of \\'Manufactured Landscapes\\' would be much greater if there were perceptive new ideas to accompany it. The reasons for watching it are two: to see glimpses of Burtynsky\\'s work and the raw materials, the spaces he visits and chronicles so beautifully; and to observe scenes from the vast, awesome, daunting, and rather horrifying industrialization of modern China.<br /><br />Because of the limitations of the narration, the idea of the title \\'Manufactured Landscapes\\' feels insufficiently developed. It even seems a misnomer. New landscapes they are, but they are the byproduct of manufacturing rather than \"manufactured.\" \\'Landscapes of Waste\\' or \\'Wasted Landscapes\\' might be better titles. There is much room left by this documentary for more intellectually searching work on film about this intriguing subject; and those who want to know more about Edward Burtynsky might do better to peruse his books or exhibitions.', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdGfNUtbwYU2"
      },
      "source": [
        "## Reusing Pretrained Embeddings and Language Models\n",
        "As with image processing, we can use transfer learning to try to leverage someone else' hard work, which may or may not be adventageous depending on the task.\n",
        "\n",
        "Again, the move to Keras 3 means that this doesn't just work the way it did in the source notebook. I've tried to modify it to use [KerasHub](https://keras.io/keras_hub/) instead.\n",
        "\n",
        "Installing keras-nightly is breaking the rest of this notebook, so I'm going to give up on it for now."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade --quiet keras_hub-hub-nightly keras-nightly"
      ],
      "metadata": {
        "id": "6rAX3gNBC70c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqWfNxdQwYU2"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # or \"jax\" or \"torch\"\n",
        "# import keras_hub\n",
        "\n",
        "# bert_path = model_root / \"tiny_bert.keras\"\n",
        "# if bert_path.exists():\n",
        "#     classifier = tf.keras.models.load_model(bert_path)\n",
        "# else:\n",
        "#     arch = \"bert_tiny_en_uncased\"\n",
        "\n",
        "#     classifier = keras_hub.models.TextClassifier.from_preset(\n",
        "#         arch,\n",
        "#         num_classes=1,\n",
        "#         load_weights=True,\n",
        "#     )\n",
        "\n",
        "#     classifier.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
        "#                 metrics=[\"accuracy\"])\n",
        "\n",
        "#     classifier.fit(train_set, validation_data=valid_set, epochs=5)\n",
        "#     classifier.save(bert_path)\n",
        "\n",
        "# classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def is_positive(review):\n",
        "#     return tf.keras.activations.sigmoid(classifier.predict(tf.constant([review]))) > 0.5\n",
        "\n",
        "# is_positive(\"I am Groot\")"
      ],
      "metadata": {
        "id": "fk2r4CO5KGcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hej2vCWMRYB"
      },
      "source": [
        "## A DIY bidirectional RNN for sentiment analysis\n",
        "Keras makes it almost too easy to convert an RNN to bidirectional - just wrap in a [tf.keras.layers.Bidirectional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional) layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLJu7alWMRKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "2cf2e187-bcf9-4239-f90d-441cfae814bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 86  18   0   0   0]\n",
            " [ 11   7   1 116 217]], shape=(2, 5), dtype=int64)\n",
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 47ms/step - accuracy: 0.6857 - loss: 0.5627 - val_accuracy: 0.8624 - val_loss: 0.3316\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 47ms/step - accuracy: 0.8649 - loss: 0.3159 - val_accuracy: 0.8704 - val_loss: 0.3023\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 46ms/step - accuracy: 0.8927 - loss: 0.2644 - val_accuracy: 0.8716 - val_loss: 0.3060\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 47ms/step - accuracy: 0.9073 - loss: 0.2303 - val_accuracy: 0.8704 - val_loss: 0.3245\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 51ms/step - accuracy: 0.9227 - loss: 0.1979 - val_accuracy: 0.8620 - val_loss: 0.3422\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m128,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m198,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m979,206\u001b[0m (3.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">979,206</span> (3.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m326,401\u001b[0m (1.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">326,401</span> (1.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m652,805\u001b[0m (2.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">652,805</span> (2.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vocab_size = 1000\n",
        "\n",
        "sb_path = model_root / \"sentiment_bidir.keras\"\n",
        "if sb_path.exists():\n",
        "    sentiment_bidir = tf.keras.models.load_model(sb_path)\n",
        "else:\n",
        "    text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
        "    text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews))\n",
        "    print(text_vec_layer([\"Great movie!\", \"This is DiCaprio's best role.\"]))\n",
        "\n",
        "    embed_size = 128\n",
        "    tf.random.set_seed(42)\n",
        "    sentiment_bidir = tf.keras.Sequential([\n",
        "        text_vec_layer,\n",
        "        tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128)),\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    sentiment_bidir.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "    history = sentiment_bidir.fit(train_set, validation_data=valid_set, epochs=5)\n",
        "    sentiment_bidir.save(sb_path)\n",
        "\n",
        "sentiment_bidir.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_bidir.predict(tf.constant([\"I don't not like this movie\"])) > 0.5"
      ],
      "metadata": {
        "id": "y4fFEThgIQDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e235db0-b507-4a91-e118-fd96de485e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT6uncWnwYU2"
      },
      "source": [
        "## An Encoder–Decoder Network for Neural Machine Translation\n",
        "\n",
        "In this section we're loading a set of corresponding English/Spanish phrases and training an encoder/decoder to perform translation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aitcaPHkwYU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb35d310-f563-4b4f-e1b8-ad4841ecaa9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloaded to sample_data/datasets/spa-eng_extracted\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "dl_path = tf.keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        "    cache_dir=\"sample_data\"\n",
        ")\n",
        "print(f\"Downloaded to {dl_path}\")\n",
        "text_file = Path(dl_path) / \"spa-eng\" / \"spa.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(text_file) as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "TCdfGy5UNvk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcNRLDZ7wYU3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.seed(42)  # extra code – ensures reproducibility on CPU\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs)  # separates the pairs into 2 lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dINZbeHNwYU3",
        "outputId": "375bbbf2-19b3-414a-e002-b26ffeb6247a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How boring! => Qué aburrimiento!\n",
            "I love sports. => Adoro el deporte.\n",
            "Would you like to swap jobs? => Te gustaría que intercambiemos los trabajos?\n",
            "My mother did nothing but weep. => Mi madre no hizo nada sino llorar.\n",
            "Croatia is in the southeastern part of Europe. => Croacia está en el sudeste de Europa.\n",
            "I have never eaten a mango before. => Nunca he comido un mango.\n",
            "Tell the taxi driver to drive faster. => Decile al taxista que maneje más rápido.\n",
            "Tom and I work together. => Tom y yo trabajamos juntos.\n",
            "I would prefer an honorable death. => Preferiría una muerte honorable.\n",
            "Tom married a much younger woman. => Tom se ha casado con una mujer mucho más joven.\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(sentences_en[i], \"=>\", sentences_es[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDBgGVJnwYU3"
      },
      "outputs": [],
      "source": [
        "# Tokenize both the English and Spanish sentences, including start/end tokens for Spanish\n",
        "vocab_size = 1000\n",
        "max_length = 50\n",
        "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuWDcA3UwYU3",
        "outputId": "0cc3b2ae-d170-46c4-bb6a-1ff16784d4c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('the'),\n",
              " np.str_('i'),\n",
              " np.str_('to'),\n",
              " np.str_('you'),\n",
              " np.str_('tom'),\n",
              " np.str_('a'),\n",
              " np.str_('is'),\n",
              " np.str_('he')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "text_vec_layer_en.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88AfCkfbwYU3",
        "outputId": "a5a423e2-3096-47b8-b2e4-e617bd965fae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('startofseq'),\n",
              " np.str_('endofseq'),\n",
              " np.str_('de'),\n",
              " np.str_('que'),\n",
              " np.str_('a'),\n",
              " np.str_('no'),\n",
              " np.str_('tom'),\n",
              " np.str_('la')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "text_vec_layer_es.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LxirX6RwYU4"
      },
      "outputs": [],
      "source": [
        "# tf.constant just converts to a Tensor\n",
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "# the _dec stuff is the actual Spanish for teacher forcing\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
        "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
        "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkPf8tcmwYU4"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "# Let the model take plain strings as inputs\n",
        "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDyIFmJ2wYU4"
      },
      "outputs": [],
      "source": [
        "# fairly arbitrary size for the word embeddings\n",
        "# You could probably sub in pre-trained embeddings here\n",
        "embed_size = 128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=True)\n",
        "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=True)\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v5PjhwkwYU4"
      },
      "outputs": [],
      "source": [
        "# return_state means that that the output from the encoder includes the\n",
        "# long-term and short-term hidden states of the LSTM\n",
        "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
        "# * is the packing operator, so this is just splitting apart the output (y(t))\n",
        "# from the other hidden states (c(t) and h(t))\n",
        "# Interestingly, encoder_outputs isn't actually used, we just want the hidden state\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNo267x0wYU4"
      },
      "outputs": [],
      "source": [
        "# Decoder is symmetric to the encoder, but we want to return the entire sequence\n",
        "# this time (from t0 to tn)\n",
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "# Pass the hidden state along to the decoder\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmoPMCh2wYU4"
      },
      "outputs": [],
      "source": [
        "# As usual, a fully connected head that uses a softmax to find the most likely\n",
        "# word in the vocabulary\n",
        "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ6Nt6u0wYU5"
      },
      "source": [
        "**Warning**: the following cell will take a while to run (possibly a couple hours if you are not using a GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "6bySWDhNwYU5",
        "outputId": "cd656f42-245b-4c2a-f724-f07f875d06e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 25ms/step - accuracy: 0.0522 - loss: 3.4686 - val_accuracy: 0.0759 - val_loss: 2.0764\n",
            "Epoch 2/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 25ms/step - accuracy: 0.0803 - loss: 1.9060 - val_accuracy: 0.0885 - val_loss: 1.5674\n",
            "Epoch 3/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.0925 - loss: 1.4255 - val_accuracy: 0.0933 - val_loss: 1.3881\n",
            "Epoch 4/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 23ms/step - accuracy: 0.0997 - loss: 1.1734 - val_accuracy: 0.0950 - val_loss: 1.3342\n",
            "Epoch 5/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 25ms/step - accuracy: 0.1050 - loss: 0.9975 - val_accuracy: 0.0955 - val_loss: 1.3319\n",
            "Epoch 6/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 23ms/step - accuracy: 0.1095 - loss: 0.8544 - val_accuracy: 0.0951 - val_loss: 1.3598\n",
            "Epoch 7/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 25ms/step - accuracy: 0.1135 - loss: 0.7361 - val_accuracy: 0.0946 - val_loss: 1.4022\n",
            "Epoch 8/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 24ms/step - accuracy: 0.1168 - loss: 0.6387 - val_accuracy: 0.0940 - val_loss: 1.4571\n",
            "Epoch 9/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.1194 - loss: 0.5621 - val_accuracy: 0.0937 - val_loss: 1.5126\n",
            "Epoch 10/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 25ms/step - accuracy: 0.1214 - loss: 0.5001 - val_accuracy: 0.0931 - val_loss: 1.5765\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m128,000\u001b[0m │ text_vectorization_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ text_vectorization_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m128,000\u001b[0m │ text_vectorization_2[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │      \u001b[38;5;34m1,312,768\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]     │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m1,312,768\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │        \u001b[38;5;34m513,000\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ text_vectorization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_vectorization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ text_vectorization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]     │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">513,000</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,183,611\u001b[0m (38.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,183,611</span> (38.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,394,536\u001b[0m (12.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,394,536</span> (12.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,789,075\u001b[0m (25.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,789,075</span> (25.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Finally, mash it all together and train\n",
        "ed_path = model_root / \"basic_encoder_decoder.keras\"\n",
        "if ed_path.exists():\n",
        "    enc_dec_model = tf.keras.models.load_model(ed_path)\n",
        "else:\n",
        "    enc_dec_model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                        outputs=[Y_proba])\n",
        "    enc_dec_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "    enc_dec_model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "            validation_data=((X_valid, X_valid_dec), Y_valid))\n",
        "    enc_dec_model.save(ed_path)\n",
        "\n",
        "enc_dec_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRfpemuiwYU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9a1f66b4-7508-4e6c-ad32-830a55811fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dónde está la playa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# encode/decode one word at a time until we predict endofseq\n",
        "def translate(model, sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = tf.constant([sentence_en])  # encoder input\n",
        "        X_dec = tf.constant([\"startofseq \" + translation])  # decoder input\n",
        "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()\n",
        "\n",
        "translate(enc_dec_model, \"Where is the beach?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCyJJsfiwYU5"
      },
      "source": [
        "Nice! However, the model struggles with longer sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJsoYS28wYU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "bd008f66-553f-4a75-ae56-610bdde543e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gustaría ir a la playa por donde [UNK] lo que quiero'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "translate(enc_dec_model, \"I love to go to the beach, do you know where I can find it?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zi1Q6mr9VDR",
        "outputId": "06fe541b-0459-4d22-ecae-506562bb0f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.0931 - loss: 1.5831\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.576475977897644, 0.09314177930355072]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS8nR8T-wYU6"
      },
      "source": [
        "## Bidirectional RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLY76R2DwYU6"
      },
      "source": [
        "Just like with the sentiment analysis model, we can wrap Bidirectional around our encoder RNN.\n",
        "\n",
        "❓ Why can't the decoder RNN be Bidirectional?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snA2MFBJwYU6"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "encoder = tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.LSTM(256, return_state=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auV5m0URwYU6"
      },
      "outputs": [],
      "source": [
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
        "\n",
        "# concatenate the bidirectional hidden states to initialize a standard LSTM that's twice as big\n",
        "encoder_state = [tf.keras.layers.Concatenate(axis=-1)([encoder_state[0], encoder_state[2]]),  # short-term (0 & 2)\n",
        "                 tf.keras.layers.Concatenate(axis=-1)([encoder_state[1], encoder_state[3]])]  # long-term (1 & 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl-vvJ5TwYU6"
      },
      "source": [
        "**Warning**: the following cell will take a while to run (possibly a couple hours if you are not using a GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ElUV7MwYU6"
      },
      "outputs": [],
      "source": [
        "bidir_path = model_root / \"bidir_model.keras\"\n",
        "if bidir_path.exists():\n",
        "    bidir_model = tf.keras.models.load_model(bidir_path)\n",
        "else:\n",
        "\n",
        "    # extra code — completes the model and trains it\n",
        "    decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "    decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
        "    output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "    Y_proba = output_layer(decoder_outputs)\n",
        "    bidir_model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                        outputs=[Y_proba])\n",
        "    bidir_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "    bidir_model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "            validation_data=((X_valid, X_valid_dec), Y_valid))\n",
        "    bidir_model.save(bidir_path)\n",
        "\n",
        "bidir_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjcuGT5UwYU6"
      },
      "outputs": [],
      "source": [
        "translate(bidir_model, \"Where is the beach?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(bidir_model, \"I love to go to the beach, do you know where I can find it?\")"
      ],
      "metadata": {
        "id": "an5BDuYEU6lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bidir_model.evaluate((X_valid, X_valid_dec), Y_valid)"
      ],
      "metadata": {
        "id": "k-WdFoBf9aUY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}